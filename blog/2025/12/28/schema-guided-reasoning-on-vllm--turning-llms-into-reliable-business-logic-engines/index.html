
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A practical guide to Schema-Guided Reasoning (SGR) on vLLM with xgrammar ‚Äî what it is, how it differs from CoT and prompt engineering, the core patterns (Cascade, Routing, Cycle), and a working implementation example.">
      
      
        <meta name="author" content="Viacheslav Dubrov">
      
      
        <link rel="canonical" href="https://slavadubrov.github.io/blog/2025/12/28/schema-guided-reasoning-on-vllm--turning-llms-into-reliable-business-logic-engines/">
      
      
        <link rel="prev" href="../../../10/22/lorax-playbook---orchestrating-thousands-of-lora-adapters-on-kubernetes/">
      
      
        <link rel="next" href="../../../../2026/01/04/the-complete-guide-to-llm-fine-tuning-in-2025-from-theory-to-production/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../../../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../../../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../../../../assets/favicon-eoc.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.23">
    
    
      
        <title>Schema-Guided Reasoning on vLLM ‚Äî Turning LLMs into Reliable Business Logic Engines - Edge of Context: Practical AI Engineering</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/brand.css">
    
      <link rel="stylesheet" href="../../../../../assets/blog-sidebar.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
     
<style>
  /* Header social icons */
  .md-header__social {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    margin-left: 0.5rem;
  }
  .md-header__social a {
    color: var(--md-primary-bg-color);
    opacity: 0.7;
    transition: opacity 0.2s;
  }
  .md-header__social a:hover {
    opacity: 1;
  }
  .md-header__social svg {
    width: 1.2rem;
    height: 1.2rem;
    fill: currentColor;
  }
  /* Adjust search to make room for social icons */
  .md-search {
    margin-right: 0;
  }
</style>

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#schema-guided-reasoning-on-vllm-turning-llms-into-reliable-business-logic-engines" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
     
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="Edge of Context: Practical AI Engineering" class="md-header__button md-logo" aria-label="Edge of Context: Practical AI Engineering" data-md-component="logo">
      
  <img src="../../../../../assets/logo-eoc.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Edge of Context: Practical AI Engineering
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Schema-Guided Reasoning on vLLM ‚Äî Turning LLMs into Reliable Business Logic Engines
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../../" class="md-tabs__link">
          
  
  
    
  
  Blog

        </a>
      </li>
    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../../about/" class="md-tabs__link">
        
  
  
    
  
  About

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
<script>
  // Inject social icons into header after DOM loads
  document.addEventListener("DOMContentLoaded", function () {
    const header = document.querySelector(".md-header__inner");
    if (header) {
      const social = document.createElement("div");
      social.className = "md-header__social";
      social.innerHTML = `
      <a href="https://www.linkedin.com/in/slavadubrov" title="LinkedIn" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
      </a>
      <a href="https://slavadubrov.substack.com/" title="Substack" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22.539 8.242H1.46V5.406h21.08v2.836zM1.46 10.812V24L12 18.11 22.54 24V10.812H1.46zM22.54 0H1.46v2.836h21.08V0z"/></svg>
      </a>
      <a href="https://github.com/slavadubrov" title="GitHub" target="_blank" rel="noopener">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
      </a>
    `;
      header.appendChild(social);
    }
  });
</script>

    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
                
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" hidden>
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="Edge of Context: Practical AI Engineering" class="md-nav__button md-logo" aria-label="Edge of Context: Practical AI Engineering" data-md-component="logo">
      
  <img src="../../../../../assets/logo-eoc.svg" alt="logo">

    </a>
    Edge of Context: Practical AI Engineering
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Blog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Blog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Archive
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Archive
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2026/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2026
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../archive/2025/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2025
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Topics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Topics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/ai-engineering/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    AI Engineering
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/agentic-ai/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Agentic AI
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/infrastructure/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Infrastructure
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/python/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
  
  
    <li class="md-nav__item">
      <a href="../../../../category/tooling/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tooling
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../about/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    About
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
                
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tldr" class="md-nav__link">
    <span class="md-ellipsis">
      TL;DR
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#what-is-schema-guided-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      What is Schema-Guided Reasoning?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="What is Schema-Guided Reasoning?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#why-sgr-matters" class="md-nav__link">
    <span class="md-ellipsis">
      Why SGR Matters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sgr-vs-chain-of-thought-vs-prompt-engineering" class="md-nav__link">
    <span class="md-ellipsis">
      SGR vs Chain of Thought vs Prompt Engineering
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SGR vs Chain of Thought vs Prompt Engineering">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#the-comparison" class="md-nav__link">
    <span class="md-ellipsis">
      The Comparison
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#prompt-engineering-semantic-persuasion" class="md-nav__link">
    <span class="md-ellipsis">
      Prompt Engineering: Semantic Persuasion
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#chain-of-thought-better-reasoning-same-structure-problems" class="md-nav__link">
    <span class="md-ellipsis">
      Chain of Thought: Better Reasoning, Same Structure Problems
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sgr-structured-chain-of-thought" class="md-nav__link">
    <span class="md-ellipsis">
      SGR: Structured Chain of Thought
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sgr-patterns" class="md-nav__link">
    <span class="md-ellipsis">
      SGR Patterns
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SGR Patterns">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-cascade-sequential-reasoning-steps" class="md-nav__link">
    <span class="md-ellipsis">
      1. Cascade: Sequential Reasoning Steps
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-routing-semantic-switch-statement" class="md-nav__link">
    <span class="md-ellipsis">
      2. Routing: Semantic Switch Statement
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-cycle-repeated-reasoning-with-lists" class="md-nav__link">
    <span class="md-ellipsis">
      3. Cycle: Repeated Reasoning with Lists
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#making-sgr-work-constrained-decoding" class="md-nav__link">
    <span class="md-ellipsis">
      Making SGR Work: Constrained Decoding
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Making SGR Work: Constrained Decoding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supported-cloud-providers" class="md-nav__link">
    <span class="md-ellipsis">
      Supported Cloud Providers
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#supported-inference-engines" class="md-nav__link">
    <span class="md-ellipsis">
      Supported Inference Engines
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-this-article-focuses-on-vllm-xgrammar" class="md-nav__link">
    <span class="md-ellipsis">
      Why This Article Focuses on vLLM + xgrammar
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-xgrammar-enforces-schemas" class="md-nav__link">
    <span class="md-ellipsis">
      How xgrammar Enforces Schemas
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How xgrammar Enforces Schemas">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#where-does-masking-happen" class="md-nav__link">
    <span class="md-ellipsis">
      Where Does Masking Happen?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#the-two-phase-process" class="md-nav__link">
    <span class="md-ellipsis">
      The Two-Phase Process
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Two-Phase Process">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#phase-1-grammar-compilation-one-time-before-inference" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 1: Grammar Compilation (one-time, before inference)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#phase-2-runtime-mask-generation-every-token" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 2: Runtime Mask Generation (every token)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#why-pushdown-automata-matter" class="md-nav__link">
    <span class="md-ellipsis">
      Why Pushdown Automata Matter
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#concrete-example-generating-a-float-field" class="md-nav__link">
    <span class="md-ellipsis">
      Concrete Example: Generating a Float Field
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#performance-why-near-zero-overhead" class="md-nav__link">
    <span class="md-ellipsis">
      Performance: Why "Near-Zero Overhead"?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#practical-implementation-with-vllm" class="md-nav__link">
    <span class="md-ellipsis">
      Practical Implementation with vLLM
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Practical Implementation with vLLM">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#project-structure" class="md-nav__link">
    <span class="md-ellipsis">
      Project Structure
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-define-your-schemas" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Define Your Schemas
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-create-the-llm-client-with-xgrammar" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Create the LLM Client with xgrammar
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-orchestrate-the-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Orchestrate the Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-run-vllm-with-xgrammar" class="md-nav__link">
    <span class="md-ellipsis">
      Step 4: Run vLLM with xgrammar
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-output" class="md-nav__link">
    <span class="md-ellipsis">
      Example Output
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#best-practices" class="md-nav__link">
    <span class="md-ellipsis">
      Best Practices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Best Practices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#schema-design" class="md-nav__link">
    <span class="md-ellipsis">
      Schema Design
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      vLLM Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#production-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Production Considerations
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    <span class="md-ellipsis">
      References
    </span>
  </a>
  
    <nav class="md-nav" aria-label="References">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgr-framework" class="md-nav__link">
    <span class="md-ellipsis">
      SGR Framework
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#xgrammar" class="md-nav__link">
    <span class="md-ellipsis">
      xgrammar
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#vllm" class="md-nav__link">
    <span class="md-ellipsis">
      vLLM
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#demo-project" class="md-nav__link">
    <span class="md-ellipsis">
      Demo Project
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
<div class="md-content md-content--post" data-md-component="content">
  <div
    class="md-sidebar md-sidebar--post"
    data-md-component="sidebar"
    data-md-type="navigation"
  >
    <div class="md-sidebar__scrollwrap">
      <div class="md-sidebar__inner md-post">
        <nav class="md-nav md-nav--primary">
          <div class="md-post__back">
            <div class="md-nav__title md-nav__container">
              <a href="../../../../" class="md-nav__link">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
                <span class="md-ellipsis"> Back to index </span>
              </a>
            </div>
          </div>

          
          <ul class="md-post__meta md-nav__list">
            <li class="md-nav__item md-nav__item--section">
              <div class="md-post__title">
                <span class="md-ellipsis">Topics</span>
              </div>
              <nav class="md-nav">
                        
                 
                <div
                  class="blog-category-section"
                >
                  <div class="blog-category-header">
                    <span class="blog-category-icon"
                      >ü§ñ</span
                    >
                    <span class="blog-category-name">AI Engineering</span>
                  </div>
                  <ul class="blog-category-posts">
                      
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../../2026/01/04/the-complete-guide-to-llm-fine-tuning-in-2025-from-theory-to-production/">The Complete Guide to LLM Fine-Tuning in 2025: From Theory to Production</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../10/22/lorax-playbook---orchestrating-thousands-of-lora-adapters-on-kubernetes/">LoRAX Playbook - Orchestrating Thousands of LoRA Adapters on Kubernetes</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/11/choosing-the-right-open-source-llm-variant--file-format/">Choosing the Right Open-Source LLM Variant & File Format</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/10/quick-guide-on-running-llms-locally-on-macos/">Quick-guide on Running LLMs Locally on macOS</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/04/scaling-large-language-models---practical-multi-gpu-and-multi-node-strategies-for-2025/">Scaling Large Language Models - Practical Multi-GPU and Multi-Node Strategies for 2025</a>
                    </li>
                     
                  </ul>
                </div>
                 
                <div
                  class="blog-category-section blog-category-section--active"
                >
                  <div class="blog-category-header">
                    <span class="blog-category-icon"
                      >ü¶æ</span
                    >
                    <span class="blog-category-name">Agentic AI</span>
                  </div>
                  <ul class="blog-category-posts">
                      
                    <li
                      class="blog-category-post blog-category-post--active"
                    >
                      <a href="./">Schema-Guided Reasoning on vLLM ‚Äî Turning LLMs into Reliable Business Logic Engines</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../10/20/domain-driven-design-for-ai-agents-a-beginner-friendly-guide/">Domain-driven design for AI agents: a beginner-friendly guide</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../10/05/context-engineering-in-the-agenticai-era--and-how-to-cook-it/">Context Engineering in the Agentic‚ÄëAI Era ‚Äî and How to Cook It</a>
                    </li>
                     
                  </ul>
                </div>
                 
                <div
                  class="blog-category-section"
                >
                  <div class="blog-category-header">
                    <span class="blog-category-icon"
                      >üîß</span
                    >
                    <span class="blog-category-name">Infrastructure</span>
                  </div>
                  <ul class="blog-category-posts">
                      
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/06/mlops-in-the-age-of-foundation-models-evolving-infrastructure-for-llms-and-beyond/">MLOps in the Age of Foundation Models. Evolving Infrastructure for LLMs and Beyond</a>
                    </li>
                     
                  </ul>
                </div>
                 
                <div
                  class="blog-category-section"
                >
                  <div class="blog-category-header">
                    <span class="blog-category-icon"
                      >üõ†Ô∏è</span
                    >
                    <span class="blog-category-name">Tooling</span>
                  </div>
                  <ul class="blog-category-posts">
                      
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../06/10/building-a-custom-featurestorelite-mcp-server-using-uv/">Building a Custom FeatureStoreLite MCP Server Using uv</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/10/quick-guide-on-local-stable-diffusion-toolkits-for-macos/">Quick-guide on Local Stable-Diffusion Toolkits for macOS</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/07/mastering-zsh-startup-zprofile-vs-zshrc-/">Mastering Zsh Startup: ~/.zprofile vs ~/.zshrc üöÄ</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../04/19/quick-guide-on-setting-up-a-macbook-for-ai-engineering/">Quick-Guide on setting up a MacBook for AI Engineering</a>
                    </li>
                     
                  </ul>
                </div>
                 
                <div
                  class="blog-category-section"
                >
                  <div class="blog-category-header">
                    <span class="blog-category-icon"
                      >üêç</span
                    >
                    <span class="blog-category-name">Python</span>
                  </div>
                  <ul class="blog-category-posts">
                      
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../05/08/the-ultimate-guide-to-pyprojecttoml/">The Ultimate Guide to `pyproject.toml`</a>
                    </li>
                    
                    <li
                      class="blog-category-post"
                    >
                      <a href="../../../04/17/quick-guide-managing-python-on-macos-with-uv/">Quick Guide: Managing Python on macOS with uv</a>
                    </li>
                     
                  </ul>
                </div>
                
              </nav>
            </li>
          </ul>

          
        </nav>
        
      </div>
    </div>
  </div>
  <article class="md-content__inner md-typeset">
     
  




<h1 id="schema-guided-reasoning-on-vllm-turning-llms-into-reliable-business-logic-engines">Schema-Guided Reasoning on vLLM ‚Äî Turning LLMs into Reliable Business Logic Engines</h1>
<h2 id="tldr">TL;DR</h2>
<blockquote>
<p><strong>Schema-Guided Reasoning (SGR)</strong> is a technique that forces LLMs to reason through predefined steps by enforcing structured output schemas. Instead of hoping the model follows your formatting instructions, you <strong>guarantee</strong> it with constrained decoding. Combined with vLLM's xgrammar backend, you get 100% valid JSON output with near-zero latency overhead.</p>
</blockquote>
<p><strong>The problem</strong>: You build an LLM-powered agent. It works in demos. In production, it outputs malformed JSON, skips reasoning steps, and gives inconsistent responses. You add retry loops, validation layers, larger models. Costs explode.</p>
<p><strong>The fix</strong>: Define your reasoning topology as a Pydantic schema. Let xgrammar enforce it at the token generation level. The LLM physically cannot produce invalid output.</p>
<!-- more -->

<hr />
<h2 id="what-is-schema-guided-reasoning">What is Schema-Guided Reasoning?</h2>
<p>Schema-Guided Reasoning (SGR) is a technique pioneered by <a href="https://abdullin.com/schema-guided-reasoning/">Rinat Abdullin</a> that guides LLMs to produce structured, clear, and predictable outputs by enforcing reasoning through predefined steps.</p>
<p>Instead of allowing free-form text completion (which can be inconsistent or ambiguous), the schema acts as a strict guideline. By creating a specific schema (or structured template), you explicitly define:</p>
<ul>
<li><strong>What steps</strong> the model must go through (preventing skipped reasoning)</li>
<li><strong>In which order</strong> it must reason (ensuring logical flow)</li>
<li><strong>Where it should focus</strong> attention (improving depth and accuracy)</li>
</ul>
<p>Think of it as giving the model a "cognitive checklist" that it <strong>must</strong> follow.</p>
<p><img alt="SGR Overview" src="../../../../assets/2025-12-25-sgr-vllm/sgr_overview.svg" /></p>
<h3 id="why-sgr-matters">Why SGR Matters</h3>
<p>The core insight is simple but powerful:</p>
<blockquote>
<p><strong>Schema = Cognitive Scaffold</strong></p>
</blockquote>
<p>When you define a schema with fields like <code>churn_analysis</code>, <code>margin_math</code>, and then <code>max_discount_percent</code>, the model is <strong>forced</strong> to populate these fields in order. It cannot jump to the discount decision without first analyzing the data.</p>
<p>This translates to:</p>
<ul>
<li><strong>Reproducible reasoning</strong> ‚Äî consistent inference across repeated runs</li>
<li><strong>Auditable outputs</strong> ‚Äî every reasoning step is explicit and inspectable</li>
<li><strong>Debuggable &amp; testable</strong> ‚Äî intermediate outputs can be evaluated against test datasets</li>
<li><strong>Works with smaller models</strong> ‚Äî the schema "holds the hand" of weaker models</li>
<li><strong>5-10% accuracy boost</strong> ‚Äî <a href="https://abdullin.com/schema-guided-reasoning/">commonly observed</a> in production deployments</li>
</ul>
<hr />
<h2 id="sgr-vs-chain-of-thought-vs-prompt-engineering">SGR vs Chain of Thought vs Prompt Engineering</h2>
<p>Let's be precise about what makes SGR different from the approaches you're probably already using.</p>
<p><img alt="SGR Comparison" src="../../../../assets/2025-12-25-sgr-vllm/sgr_comparison.svg" /></p>
<h3 id="the-comparison">The Comparison</h3>
<table>
<thead>
<tr>
<th>Feature</th>
<th>Prompt Engineering</th>
<th>Chain of Thought</th>
<th>Schema-Guided Reasoning</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Output Structure</strong></td>
<td>Variable text</td>
<td>Free-form prose</td>
<td>Rigid JSON/Pydantic</td>
</tr>
<tr>
<td><strong>Control Mechanism</strong></td>
<td>Semantic persuasion ("Please output JSON")</td>
<td>Heuristic prompting ("Let's think step by step")</td>
<td>Constrained decoding (grammar-based)</td>
</tr>
<tr>
<td><strong>Reasoning Flow</strong></td>
<td>Model determines</td>
<td>Model determines</td>
<td>Developer determines (schema topology)</td>
</tr>
<tr>
<td><strong>Auditability</strong></td>
<td>Low (requires parsing)</td>
<td>Low (requires reading prose)</td>
<td>High (field-level inspection)</td>
</tr>
<tr>
<td><strong>Integration</strong></td>
<td>Difficult (regex parsing)</td>
<td>Difficult (variable format)</td>
<td>Trivial (native object deserialization)</td>
</tr>
<tr>
<td><strong>Error Rate</strong></td>
<td>High (format variability)</td>
<td>Moderate (hallucination of format)</td>
<td>Near-zero (syntax enforced by engine)</td>
</tr>
<tr>
<td><strong>Model Requirement</strong></td>
<td>Strong instruction following</td>
<td>Strong reasoning capability</td>
<td>Works with smaller models too</td>
</tr>
</tbody>
</table>
<h3 id="prompt-engineering-semantic-persuasion">Prompt Engineering: Semantic Persuasion</h3>
<div class="highlight"><pre><span></span><code>Please analyze the customer data and output your response as valid JSON
with the following structure: {&quot;discount&quot;: &lt;number&gt;, &quot;reason&quot;: &lt;string&gt;}
Be careful with the formatting!
</code></pre></div>
<p><strong>The problem</strong>: You're <em>hoping</em> the model's semantic understanding of "output JSON" outweighs its tendency to be conversational. A model update, temperature change, or different few-shot examples can break your parser.</p>
<h3 id="chain-of-thought-better-reasoning-same-structure-problems">Chain of Thought: Better Reasoning, Same Structure Problems</h3>
<div class="highlight"><pre><span></span><code>Let&#39;s think step by step:
1. First, I&#39;ll analyze the customer&#39;s churn risk...
2. Then I&#39;ll calculate the margin...
3. Therefore, I recommend a 15% discount.
</code></pre></div>
<p>CoT improves reasoning <strong>accuracy</strong> but makes structure <strong>worse</strong>. The output is unpredictable prose that's nearly impossible to parse reliably. You end up needing a second LLM call to extract structured data from the reasoning.</p>
<h3 id="sgr-structured-chain-of-thought">SGR: Structured Chain of Thought</h3>
<p>SGR doesn't abandon CoT's insight that intermediate reasoning improves accuracy. It <strong>formalizes</strong> it:</p>
<div class="highlight"><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PricingLogic</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="c1"># 1. Data Analysis (must complete before decision)</span>
    <span class="n">churn_analysis</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Analyze churn_probability&quot;</span><span class="p">)</span>
    <span class="n">financial_analysis</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Analyze cart_value and margin&quot;</span><span class="p">)</span>

    <span class="c1"># 2. Math Enforcement (explicit calculation)</span>
    <span class="n">margin_math</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Calculate: &#39;Cart $X * Y% = $Z&#39;&quot;</span><span class="p">)</span>

    <span class="c1"># 3. Decision Constraint (bounded by prior analysis)</span>
    <span class="n">max_discount_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Max allowed discount&quot;</span><span class="p">)</span>

    <span class="c1"># 4. Final Output</span>
    <span class="n">offer_code</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">customer_message</span><span class="p">:</span> <span class="nb">str</span>
</code></pre></div>
<p>The model <strong>cannot</strong> output <code>max_discount_percent</code> without first populating <code>churn_analysis</code>, <code>financial_analysis</code>, and <code>margin_math</code>. The schema enforces the reasoning order.</p>
<hr />
<h2 id="sgr-patterns">SGR Patterns</h2>
<p>SGR enables three foundational patterns for controlling LLM reasoning. These can be combined for complex workflows.</p>
<p><img alt="SGR Patterns" src="../../../../assets/2025-12-25-sgr-vllm/sgr_patterns.svg" /></p>
<h3 id="1-cascade-sequential-reasoning-steps">1. Cascade: Sequential Reasoning Steps</h3>
<p>Cascade ensures the model follows predefined reasoning steps in order. Each field must be completed before the next.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Annotated</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">annotated_types</span><span class="w"> </span><span class="kn">import</span> <span class="n">Ge</span><span class="p">,</span> <span class="n">Le</span>

<span class="k">class</span><span class="w"> </span><span class="nc">CandidateEvaluation</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate a job candidate with enforced reasoning order.&quot;&quot;&quot;</span>

    <span class="c1"># Step 1: Summarize (forces context awareness)</span>
    <span class="n">brief_candidate_summary</span><span class="p">:</span> <span class="nb">str</span>

    <span class="c1"># Step 2: Rate (bounded integer)</span>
    <span class="n">rate_skill_match</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Ge</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">Le</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>

    <span class="c1"># Step 3: Decide (constrained choices)</span>
    <span class="n">final_recommendation</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;hire&quot;</span><span class="p">,</span> <span class="s2">&quot;reject&quot;</span><span class="p">,</span> <span class="s2">&quot;hold&quot;</span><span class="p">]</span>
</code></pre></div>
<p><strong>Use cases</strong>: Candidate evaluation, document classification, compliance analysis, medical diagnosis</p>
<p><strong>Key insight</strong>: The model must complete <code>brief_candidate_summary</code> before it can rate, and must rate before it can recommend. No shortcuts allowed.</p>
<hr />
<h3 id="2-routing-semantic-switch-statement">2. Routing: Semantic Switch Statement</h3>
<p>Routing forces the model to explicitly choose one path from multiple options. This is implemented using <code>Union</code> types.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Union</span>

<span class="k">class</span><span class="w"> </span><span class="nc">FeatureLookup</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Route to database lookup.&quot;&quot;&quot;</span>
    <span class="n">rationale</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">tool_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;fetch_user_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;fetch_user_features&quot;</span>
    <span class="n">user_id</span><span class="p">:</span> <span class="nb">str</span>

<span class="k">class</span><span class="w"> </span><span class="nc">GeneralResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard response for non-pricing queries.&quot;&quot;&quot;</span>
    <span class="n">tool_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;respond&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;respond&quot;</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">str</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RouterSchema</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The model must pick exactly ONE branch.&quot;&quot;&quot;</span>
    <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FeatureLookup</span><span class="p">,</span> <span class="n">GeneralResponse</span><span class="p">]</span>
</code></pre></div>
<p><strong>Use cases</strong>: Intent classification, tool selection, support triage, multi-agent dispatch</p>
<p><strong>Key insight</strong>: The <code>Literal</code> type with a discriminator field (like <code>tool_name</code>) ensures the model commits to one branch and fills in the required fields for that specific path.</p>
<hr />
<h3 id="3-cycle-repeated-reasoning-with-lists">3. Cycle: Repeated Reasoning with Lists</h3>
<p>Cycle forces the model to produce multiple items, with constraints on minimum and maximum count.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Annotated</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">annotated_types</span><span class="w"> </span><span class="kn">import</span> <span class="n">MinLen</span><span class="p">,</span> <span class="n">MaxLen</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RiskFactor</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">explanation</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">severity</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;low&quot;</span><span class="p">,</span> <span class="s2">&quot;medium&quot;</span><span class="p">,</span> <span class="s2">&quot;high&quot;</span><span class="p">]</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RiskAssessment</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate 2-4 risk factors.&quot;&quot;&quot;</span>
    <span class="n">factors</span><span class="p">:</span> <span class="n">Annotated</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">RiskFactor</span><span class="p">],</span> <span class="n">MinLen</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span> <span class="n">MaxLen</span><span class="p">(</span><span class="mi">4</span><span class="p">)]</span>
</code></pre></div>
<p><strong>Use cases</strong>: Risk assessment, issue extraction, parallel tool calls, multi-step planning</p>
<p><strong>Key insight</strong>: The <code>MinLen</code> and <code>MaxLen</code> annotations force the model to generate at least 2 but no more than 4 items. Combined with Routing, this enables parallel tool dispatch.</p>
<hr />
<h2 id="making-sgr-work-constrained-decoding">Making SGR Work: Constrained Decoding</h2>
<p>The patterns above are powerful, but they're just Pydantic schemas ‚Äî how do we actually <strong>enforce</strong> them? The answer is <strong>Constrained Decoding</strong> (also called Structured Output).</p>
<p>Constrained Decoding works by modifying the token generation process. Instead of allowing the model to freely sample from its vocabulary, the decoding engine applies a <strong>grammar mask</strong> that blocks tokens that would violate the schema. This happens at the inference engine level, not in your application code.</p>
<blockquote>
<p>[!TIP]
SGR doesn't require "reasoning models" (like o1 or DeepSeek-R1). It works well with instruction-tuned models, and especially well with models distilled from reasoning models.</p>
</blockquote>
<h3 id="supported-cloud-providers">Supported Cloud Providers</h3>
<p>Most modern LLM providers now support Structured Outputs via constrained decoding:</p>
<table>
<thead>
<tr>
<th>Provider</th>
<th>Support</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>OpenAI</strong></td>
<td><a href="https://platform.openai.com/docs/guides/structured-outputs">Structured Outputs</a> (including Azure). <a href="https://abdullin.com/schema-guided-reasoning/">GPT-5 uses JSON Schema via llguidance</a></td>
</tr>
<tr>
<td><strong>Google/Gemini</strong></td>
<td><a href="https://ai.google.dev/gemini-api/docs/structured-output">JSON Schema</a> support since Nov 2025 (Pydantic and Zod)</td>
</tr>
<tr>
<td><strong>Mistral</strong></td>
<td><a href="https://docs.mistral.ai/capabilities/structured-output/custom_structured_output/">Custom Structured Output</a></td>
</tr>
<tr>
<td><strong>Grok</strong></td>
<td><a href="https://docs.x.ai/docs/guides/structured-outputs">Structured Outputs</a> for multiple models</td>
</tr>
<tr>
<td><strong>Fireworks AI</strong></td>
<td><a href="https://docs.fireworks.ai/structured-responses/structured-response-formatting">JSON Schema</a></td>
</tr>
<tr>
<td><strong>Cerebras</strong></td>
<td><a href="https://inference-docs.cerebras.ai/capabilities/structured-outputs">Structured Outputs</a></td>
</tr>
<tr>
<td><strong>OpenRouter</strong></td>
<td>Depends on downstream provider, maps to JSON Schema</td>
</tr>
</tbody>
</table>
<h3 id="supported-inference-engines">Supported Inference Engines</h3>
<p>For self-hosted models, most modern inference engines support constrained decoding:</p>
<table>
<thead>
<tr>
<th>Engine</th>
<th>Backend</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>vLLM</strong></td>
<td><a href="https://github.com/mlc-ai/xgrammar">xgrammar</a> or <a href="https://github.com/guidance-ai/llguidance">guidance</a></td>
</tr>
<tr>
<td><strong>SGLang</strong></td>
<td><a href="https://github.com/dottxt-ai/outlines">Outlines</a>, <a href="https://github.com/mlc-ai/xgrammar">XGrammar</a>, or <a href="https://github.com/guidance-ai/llguidance">llguidance</a></td>
</tr>
<tr>
<td><strong>TensorRT-LLM</strong></td>
<td><a href="https://github.com/NVIDIA/TensorRT-LLM/blob/main/examples/llm-api/llm_guided_decoding.py">GuidedDecoding</a></td>
</tr>
<tr>
<td><strong>Ollama</strong></td>
<td><a href="https://ollama.com/blog/structured-outputs">Structured Outputs</a></td>
</tr>
</tbody>
</table>
<h3 id="why-this-article-focuses-on-vllm-xgrammar">Why This Article Focuses on vLLM + xgrammar</h3>
<p>For this article, we'll dive deep into <strong>vLLM with the xgrammar backend</strong> because:</p>
<ol>
<li><strong>Production-grade</strong>: vLLM is the most widely deployed open-source LLM inference engine</li>
<li><strong>Zero-overhead</strong>: xgrammar is implemented in C++ with near-zero latency impact</li>
<li><strong>OpenAI-compatible API</strong>: Easy migration from cloud to self-hosted</li>
<li><strong>Full schema support</strong>: Handles complex nested schemas, unions, and recursive structures</li>
</ol>
<p>Let's look at how xgrammar actually enforces these schemas at the token level.</p>
<hr />
<h2 id="how-xgrammar-enforces-schemas">How xgrammar Enforces Schemas</h2>
<p>Now let's get precise about <strong>when</strong> and <strong>how</strong> xgrammar enforces your schema. Understanding this helps you debug and tune your SGR workflows.</p>
<p><img alt="xgrammar Enforcement" src="../../../../assets/2025-12-25-sgr-vllm/xgrammar_enforcement.svg" /></p>
<h3 id="where-does-masking-happen">Where Does Masking Happen?</h3>
<p>Here's the key insight: <strong>xgrammar modifies the output logits AFTER the model's forward pass, BEFORE sampling</strong>. It does not change the model itself ‚Äî it filters what tokens can be selected.</p>
<p>The standard LLM inference loop looks like this:</p>
<div class="highlight"><pre><span></span><code>1. Input tokens ‚Üí GPU Forward Pass ‚Üí Logits (probability scores for all ~128K tokens)
2. Logits ‚Üí Sampling (temperature, top-p, etc.) ‚Üí Next Token
3. Repeat until done
</code></pre></div>
<p>xgrammar inserts itself between steps 1 and 2:</p>
<div class="highlight"><pre><span></span><code>1. Input tokens ‚Üí GPU Forward Pass ‚Üí Raw Logits
2. Raw Logits ‚Üí xgrammar Logits Processor ‚Üí Masked Logits
3. Masked Logits ‚Üí Sampling ‚Üí Next Token (guaranteed valid)
4. Repeat until done
</code></pre></div>
<p>The critical point: <strong>the model computes its full probability distribution on the GPU first</strong>. Then xgrammar, running on CPU, applies a bitmask to the logits before sampling. Invalid tokens get their logits set to <code>-‚àû</code>, which makes their probability exactly 0 after softmax.</p>
<h3 id="the-two-phase-process">The Two-Phase Process</h3>
<p>xgrammar's efficiency comes from splitting the work into two phases:</p>
<h4 id="phase-1-grammar-compilation-one-time-before-inference">Phase 1: Grammar Compilation (one-time, before inference)</h4>
<div class="highlight"><pre><span></span><code><span class="c1"># This happens once per schema</span>
<span class="n">tokenizer_info</span> <span class="o">=</span> <span class="n">xgr</span><span class="o">.</span><span class="n">TokenizerInfo</span><span class="o">.</span><span class="n">from_huggingface</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
<span class="n">grammar_compiler</span> <span class="o">=</span> <span class="n">xgr</span><span class="o">.</span><span class="n">GrammarCompiler</span><span class="p">(</span><span class="n">tokenizer_info</span><span class="p">)</span>
<span class="n">compiled_grammar</span> <span class="o">=</span> <span class="n">grammar_compiler</span><span class="o">.</span><span class="n">compile_json_schema</span><span class="p">(</span><span class="n">schema_json</span><span class="p">)</span>
</code></pre></div>
<p>During compilation, xgrammar:</p>
<ol>
<li>Converts your JSON Schema to a Context-Free Grammar (CFG)</li>
<li>Builds a Pushdown Automaton (PDA) ‚Äî like a state machine with a stack for handling nested structures like <code>{"a": {"b": {"c": ...}}}</code></li>
<li>Pre-computes which tokens are valid at each grammar position (the "adaptive token mask cache")</li>
<li>Categorizes tokens as "context-independent" (can be pre-checked) or "context-dependent" (must be checked at runtime based on stack state)</li>
</ol>
<blockquote>
<p>[!NOTE]
About 99% of tokens are context-independent and can be cached (<a href="https://arxiv.org/abs/2411.15100">XGrammar paper</a>). This is why xgrammar is so fast ‚Äî most validity checks are just cache lookups.</p>
</blockquote>
<h4 id="phase-2-runtime-mask-generation-every-token">Phase 2: Runtime Mask Generation (every token)</h4>
<p>At each generation step:</p>
<ol>
<li>The <code>GrammarMatcher</code> tracks the current position in the grammar</li>
<li>It retrieves the pre-computed mask for context-independent tokens (cache lookup)</li>
<li>It runs the PDA to check the remaining context-dependent tokens</li>
<li>It combines these into a final bitmask and applies it to the logits</li>
</ol>
<h3 id="why-pushdown-automata-matter">Why Pushdown Automata Matter</h3>
<p>You might wonder: why not just use regex? The answer is <strong>nesting</strong>.</p>
<p>A regular expression (which is a Finite State Machine) cannot reliably match structures like:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span><span class="w"> </span><span class="nt">&quot;user&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;profile&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;settings&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;theme&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;dark&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">}</span>
</code></pre></div>
<p>The problem is matching the closing braces <code>}}}</code> ‚Äî you need to "remember" how many you opened. A Pushdown Automaton has a <strong>stack</strong> that tracks this context, enabling it to handle arbitrary nesting depth.</p>
<p>This is why xgrammar can enforce complex schemas with Union types, nested objects, and recursive structures ‚Äî capabilities that simpler regex-based approaches cannot match.</p>
<h3 id="concrete-example-generating-a-float-field">Concrete Example: Generating a Float Field</h3>
<p>When the model is generating <code>"max_discount_percent":</code>, xgrammar knows from the schema that a <code>float</code> comes next. The mask:</p>
<ul>
<li><strong>Allows</strong> (probability unchanged): <code>0</code>, <code>1</code>, <code>2</code>, ..., <code>9</code>, <code>.</code>, <code>-</code></li>
<li><strong>Blocks</strong> (probability ‚Üí 0): <code>"</code>, <code>{</code>, <code>[</code>, <code>true</code>, <code>false</code>, <code>null</code>, and all 128K+ other tokens</li>
</ul>
<p>The model's forward pass might have assigned high probability to the word <code>"fifteen"</code>. But after xgrammar's mask, that token has probability 0. The model <strong>must</strong> output digits.</p>
<h3 id="performance-why-near-zero-overhead">Performance: Why "Near-Zero Overhead"?</h3>
<p>Three factors make xgrammar fast:</p>
<ol>
<li>
<p><strong>Parallel execution</strong>: Mask computation (CPU) overlaps with the next forward pass (GPU). While the GPU computes logits for token N+1, the CPU computes the mask for token N.</p>
</li>
<li>
<p><strong>Caching</strong>: 99%+ of token validity is pre-computed during grammar compilation. Runtime checks are mostly cache lookups.</p>
</li>
<li>
<p><strong>C++ implementation</strong>: The hot path is optimized C++, not Python. The mask is applied directly to logits in-place.</p>
</li>
</ol>
<p>In benchmarks, xgrammar often shows <strong>negligible overhead</strong> ‚Äî and sometimes structured generation is <em>faster</em> than unconstrained generation because the constrained vocabulary reduces sampling complexity.</p>
<hr />
<h2 id="practical-implementation-with-vllm">Practical Implementation with vLLM</h2>
<p>Let's look at a complete implementation using the <a href="https://github.com/slavadubrov/sgr-discount-manager">sgr-discount-manager</a> project ‚Äî a demo that shows SGR patterns for dynamic pricing.</p>
<p><img alt="Agent Workflow" src="../../../../assets/2025-12-25-sgr-vllm/agent_workflow.svg" /></p>
<h3 id="project-structure">Project Structure</h3>
<div class="highlight"><pre><span></span><code>sgr/
‚îú‚îÄ‚îÄ agent.py            # Main orchestration
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py      # Pydantic SGR schemas
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îú‚îÄ‚îÄ routing.py      # Phase 1 prompts
‚îÇ   ‚îî‚îÄ‚îÄ pricing.py      # Phase 3 prompts
‚îú‚îÄ‚îÄ store/
‚îÇ   ‚îî‚îÄ‚îÄ hybrid_store.py # Hot/Cold data retrieval
‚îî‚îÄ‚îÄ utils/
    ‚îî‚îÄ‚îÄ llm_client.py   # LLM client wrapper with xgrammar
</code></pre></div>
<h3 id="step-1-define-your-schemas">Step 1: Define Your Schemas</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># sgr/models/schemas.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Union</span>


<span class="c1"># --- Phase 1: Routing (Union for branching) ---</span>
<span class="k">class</span><span class="w"> </span><span class="nc">FeatureLookup</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Route to DB lookup if pricing context is needed.&quot;&quot;&quot;</span>
    <span class="n">rationale</span><span class="p">:</span> <span class="nb">str</span>
    <span class="n">tool_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;fetch_user_features&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;fetch_user_features&quot;</span>
    <span class="n">user_id</span><span class="p">:</span> <span class="nb">str</span>


<span class="k">class</span><span class="w"> </span><span class="nc">GeneralResponse</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Standard response for non-pricing queries.&quot;&quot;&quot;</span>
    <span class="n">tool_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;respond&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;respond&quot;</span>
    <span class="n">content</span><span class="p">:</span> <span class="nb">str</span>


<span class="k">class</span><span class="w"> </span><span class="nc">RouterSchema</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">action</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">FeatureLookup</span><span class="p">,</span> <span class="n">GeneralResponse</span><span class="p">]</span>


<span class="c1"># --- Phase 2: Pricing Logic (Cascade for sequential reasoning) ---</span>
<span class="k">class</span><span class="w"> </span><span class="nc">PricingLogic</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Strict reasoning topology for dynamic pricing.</span>
<span class="sd">    Fields are ordered to enforce the analysis‚Üídecision flow.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># 1. Data Analysis (Reflection)</span>
    <span class="n">churn_analysis</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Analyze churn_probability (High &gt; 0.7).&quot;</span><span class="p">)</span>
    <span class="n">financial_analysis</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Analyze cart_value and profit_margin.&quot;</span><span class="p">)</span>

    <span class="c1"># 2. Hard Math Enforcement</span>
    <span class="n">margin_math</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Calculate absolute profit: &#39;Cart $200 * 0.20 Margin = $40&#39;.&quot;</span><span class="p">)</span>

    <span class="c1"># 3. The Decision Constraint</span>
    <span class="n">max_discount_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span>
        <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Max allowed discount %. NEVER exceed margin.&quot;</span><span class="p">)</span>

    <span class="c1"># 4. Final Output</span>
    <span class="n">offer_code</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Generated code (e.g. SAVE20).&quot;</span><span class="p">)</span>
    <span class="n">customer_message</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;The final polite offer text.&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-2-create-the-llm-client-with-xgrammar">Step 2: Create the LLM Client with xgrammar</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># sgr/utils/llm_client.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">openai</span><span class="w"> </span><span class="kn">import</span> <span class="n">OpenAI</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pydantic</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">TypeVar</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>

<span class="n">T</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;T&quot;</span><span class="p">,</span> <span class="n">bound</span><span class="o">=</span><span class="n">BaseModel</span><span class="p">)</span>


<span class="k">class</span><span class="w"> </span><span class="nc">LLMClient</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for vLLM with xgrammar-enforced structured generation.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:8000/v1&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">client</span> <span class="o">=</span> <span class="n">OpenAI</span><span class="p">(</span><span class="n">base_url</span><span class="o">=</span><span class="n">base_url</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;EMPTY&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_available_model</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_available_model</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Auto-detect the model running on vLLM server.&quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">models</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">list</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">models</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">id</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">pass</span>
        <span class="k">return</span> <span class="s2">&quot;Qwen/Qwen2.5-7B-Instruct&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">run_sgr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">messages</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span> <span class="n">schema_class</span><span class="p">:</span> <span class="nb">type</span><span class="p">[</span><span class="n">T</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">T</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Run inference with Schema-Guided Response constraints.</span>

<span class="sd">        Uses vLLM&#39;s guided_json with xgrammar backend to enforce</span>
<span class="sd">        strict schema constraints at the token generation level.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">schema_dict</span> <span class="o">=</span> <span class="n">schema_class</span><span class="o">.</span><span class="n">model_json_schema</span><span class="p">()</span>

        <span class="c1"># Enhance system message with schema for model guidance</span>
        <span class="n">enhanced_messages</span> <span class="o">=</span> <span class="n">messages</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">enhanced_messages</span> <span class="ow">and</span> <span class="n">enhanced_messages</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;role&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;system&quot;</span><span class="p">:</span>
            <span class="n">schema_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">schema_dict</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">enhanced_messages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="p">(</span>
                    <span class="n">enhanced_messages</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;content&quot;</span><span class="p">]</span>
                    <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Respond with JSON matching this schema:</span><span class="se">\n</span><span class="si">{</span><span class="n">schema_json</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">),</span>
            <span class="p">}</span>

        <span class="c1"># The magic: vLLM&#39;s guided_json with xgrammar backend</span>
        <span class="n">completion</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">client</span><span class="o">.</span><span class="n">chat</span><span class="o">.</span><span class="n">completions</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="n">enhanced_messages</span><span class="p">,</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>  <span class="c1"># Low temp for deterministic reasoning</span>
            <span class="n">extra_body</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">&quot;guided_json&quot;</span><span class="p">:</span> <span class="n">schema_dict</span><span class="p">,</span>  <span class="c1"># Pydantic schema as dict</span>
                <span class="s2">&quot;guided_decoding_backend&quot;</span><span class="p">:</span> <span class="s2">&quot;xgrammar&quot;</span><span class="p">,</span>  <span class="c1"># Hardware-enforced</span>
            <span class="p">},</span>
        <span class="p">)</span>

        <span class="n">raw_response</span> <span class="o">=</span> <span class="n">completion</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">message</span><span class="o">.</span><span class="n">content</span>
        <span class="k">return</span> <span class="n">schema_class</span><span class="o">.</span><span class="n">model_validate_json</span><span class="p">(</span><span class="n">raw_response</span><span class="p">)</span>
</code></pre></div>
<blockquote>
<p>[!NOTE]
The <code>guided_json</code> parameter accepts a JSON Schema dict. Combined with <code>guided_decoding_backend: "xgrammar"</code>, this ensures the LLM can only generate tokens that form valid JSON matching your schema.</p>
</blockquote>
<h3 id="step-3-orchestrate-the-agent">Step 3: Orchestrate the Agent</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># sgr/agent.py</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.models.schemas</span><span class="w"> </span><span class="kn">import</span> <span class="n">PricingLogic</span><span class="p">,</span> <span class="n">RouterSchema</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.prompts.routing</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_routing_prompt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.prompts.pricing</span><span class="w"> </span><span class="kn">import</span> <span class="n">build_pricing_context_prompt</span><span class="p">,</span> <span class="n">ASSISTANT_FETCH_MESSAGE</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.store.hybrid_store</span><span class="w"> </span><span class="kn">import</span> <span class="n">HybridFeatureStore</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">.utils.llm_client</span><span class="w"> </span><span class="kn">import</span> <span class="n">LLMClient</span>


<span class="k">def</span><span class="w"> </span><span class="nf">pricing_agent</span><span class="p">(</span><span class="n">user_query</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">user_id</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Process a pricing query with three-phase SGR workflow.&quot;&quot;&quot;</span>

    <span class="n">llm</span> <span class="o">=</span> <span class="n">LLMClient</span><span class="p">()</span>
    <span class="n">feature_store</span> <span class="o">=</span> <span class="n">HybridFeatureStore</span><span class="p">()</span>

    <span class="c1"># Build conversation history</span>
    <span class="n">history</span> <span class="o">=</span> <span class="p">[</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;system&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">build_routing_prompt</span><span class="p">(</span><span class="n">user_id</span><span class="p">)},</span>
        <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">user_query</span><span class="p">},</span>
    <span class="p">]</span>

    <span class="c1"># --- Phase 1: Routing (Uses RouterSchema) ---</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;ü§ñ Processing: &#39;</span><span class="si">{</span><span class="n">user_query</span><span class="si">}</span><span class="s2">&#39; for </span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">decision</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">run_sgr</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">RouterSchema</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üìç Routing decision: </span><span class="si">{</span><span class="n">decision</span><span class="o">.</span><span class="n">action</span><span class="o">.</span><span class="n">tool_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">decision</span><span class="o">.</span><span class="n">action</span><span class="o">.</span><span class="n">tool_name</span> <span class="o">==</span> <span class="s2">&quot;respond&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">decision</span><span class="o">.</span><span class="n">action</span><span class="o">.</span><span class="n">content</span>

    <span class="c1"># --- Phase 2: Context Retrieval ---</span>
    <span class="k">if</span> <span class="n">decision</span><span class="o">.</span><span class="n">action</span><span class="o">.</span><span class="n">tool_name</span> <span class="o">==</span> <span class="s2">&quot;fetch_user_features&quot;</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;üîç Fetching features for </span><span class="si">{</span><span class="n">user_id</span><span class="si">}</span><span class="s2">...&quot;</span><span class="p">)</span>
        <span class="n">context</span> <span class="o">=</span> <span class="n">feature_store</span><span class="o">.</span><span class="n">get_user_context</span><span class="p">(</span><span class="n">user_id</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">context</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Error: User profile not found.&quot;</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   [Data] LTV: $</span><span class="si">{</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;user_ltv&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2"> | &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Margin: </span><span class="si">{</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;cart_profit_margin&#39;</span><span class="p">,</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="c1"># Inject context into conversation</span>
        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">ASSISTANT_FETCH_MESSAGE</span><span class="p">})</span>
        <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
            <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">build_pricing_context_prompt</span><span class="p">(</span>
                <span class="n">churn_prob</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;churn_probability&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
                <span class="n">cart_val</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;current_cart_value&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
                <span class="n">margin</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;cart_profit_margin&quot;</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">),</span>
                <span class="n">user_ltv</span><span class="o">=</span><span class="n">context</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;user_ltv&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span>
            <span class="p">),</span>
        <span class="p">})</span>

        <span class="c1"># --- Phase 3: SGR Logic Execution (Uses PricingLogic) ---</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;üß† Calculating Offer (Schema Enforced)...&quot;</span><span class="p">)</span>
        <span class="n">offer</span> <span class="o">=</span> <span class="n">llm</span><span class="o">.</span><span class="n">run_sgr</span><span class="p">(</span><span class="n">history</span><span class="p">,</span> <span class="n">PricingLogic</span><span class="p">)</span>

        <span class="c1"># Audit log ‚Äî the SGR benefit: explicit reasoning traces</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   [Audit] Math: </span><span class="si">{</span><span class="n">offer</span><span class="o">.</span><span class="n">margin_math</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;   [Audit] Max Allowed: </span><span class="si">{</span><span class="n">offer</span><span class="o">.</span><span class="n">max_discount_percent</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">offer</span><span class="o">.</span><span class="n">customer_message</span>

    <span class="k">return</span> <span class="s2">&quot;I&#39;m sorry, I couldn&#39;t process your request.&quot;</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">pricing_agent</span><span class="p">(</span><span class="s2">&quot;I want a discount or I&#39;m leaving!&quot;</span><span class="p">,</span> <span class="s2">&quot;user_102&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üí¨ Final Reply: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<h3 id="step-4-run-vllm-with-xgrammar">Step 4: Run vLLM with xgrammar</h3>
<div class="highlight"><pre><span></span><code><span class="c1"># Start vLLM server with xgrammar backend (default in recent versions)</span>
python<span class="w"> </span>-m<span class="w"> </span>vllm.entrypoints.openai.api_server<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--model<span class="w"> </span>Qwen/Qwen2.5-7B-Instruct<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--port<span class="w"> </span><span class="m">8000</span>

<span class="c1"># Run the agent</span>
uv<span class="w"> </span>run<span class="w"> </span>python<span class="w"> </span>-m<span class="w"> </span>sgr.agent
</code></pre></div>
<h3 id="example-output">Example Output</h3>
<div class="highlight"><pre><span></span><code>ü§ñ Processing: &#39;I want a discount or I&#39;m leaving!&#39; for user_102
üìç Routing decision: fetch_user_features
üîç Fetching features for user_102...
   [Data] LTV: $1,500 | Margin: 20%
üß† Calculating Offer (Schema Enforced)...
   [Audit] Math: Cart $200 * 0.20 Margin = $40
   [Audit] Max Allowed: 15.0%

üí¨ Final Reply: We value your loyalty! Here&#39;s a special 15% discount
   with code SAVE15. This reflects our appreciation for your continued
   business with us.
</code></pre></div>
<p>The audit log shows exactly how the model reasoned: it calculated the margin ($40 on a $200 cart at 20% margin), and correctly bounded the discount to stay within the profit constraint.</p>
<hr />
<h2 id="best-practices">Best Practices</h2>
<h3 id="schema-design">Schema Design</h3>
<ol>
<li><strong>Order fields by reasoning flow</strong>: Put analysis fields before decision fields</li>
<li><strong>Use descriptive Field descriptions</strong>: They guide the model's attention</li>
<li><strong>Constrain with Literal and Annotated</strong>: Use <code>Literal["a", "b"]</code> for enums, <code>Annotated[int, Ge(1), Le(10)]</code> for bounds</li>
<li><strong>Keep schemas focused</strong>: One schema per reasoning phase, compose with multiple calls</li>
</ol>
<h3 id="vllm-configuration">vLLM Configuration</h3>
<ol>
<li><strong>Use low temperature</strong> (0.1-0.3) for deterministic reasoning</li>
<li><strong>Let xgrammar handle structure</strong>: Don't over-engineer prompts for formatting</li>
<li><strong>Monitor token usage</strong>: SGR typically uses fewer tokens than CoT (no verbose prose)</li>
</ol>
<h3 id="production-considerations">Production Considerations</h3>
<ol>
<li><strong>Schema versioning</strong>: Track schema changes like API versions</li>
<li><strong>Fallback handling</strong>: Even with SGR, network/server errors need graceful handling</li>
<li><strong>Audit logging</strong>: Log raw SGR outputs for compliance and debugging</li>
<li><strong>Test with edge cases</strong>: Ensure schemas handle boundary conditions</li>
</ol>
<hr />
<h2 id="conclusion">Conclusion</h2>
<p>Schema-Guided Reasoning bridges the gap between the flexibility of LLMs and the reliability requirements of production systems. By defining your reasoning topology as a Pydantic schema and letting xgrammar enforce it, you get:</p>
<ul>
<li><strong>Guaranteed valid output</strong> ‚Äî no retry loops, no parsing failures</li>
<li><strong>Explicit reasoning traces</strong> ‚Äî every step is auditable</li>
<li><strong>Smaller model viability</strong> ‚Äî the schema compensates for weaker instruction-following</li>
<li><strong>Lower costs</strong> ‚Äî fewer tokens, no retries, smaller models work</li>
</ul>
<p>The <a href="https://github.com/slavadubrov/sgr-discount-manager">sgr-discount-manager</a> demo shows how these patterns work in practice. Clone it, run it, and adapt the schemas for your use case.</p>
<hr />
<h2 id="references">References</h2>
<h3 id="sgr-framework">SGR Framework</h3>
<ul>
<li><a href="https://abdullin.com/schema-guided-reasoning/">Schema-Guided Reasoning (SGR)</a> ‚Äî Rinat Abdullin's original framework</li>
<li><a href="https://abdullin.com/schema-guided-reasoning/patterns">SGR Patterns</a> ‚Äî Cascade, Routing, Cycle patterns</li>
</ul>
<h3 id="xgrammar">xgrammar</h3>
<ul>
<li><a href="https://arxiv.org/abs/2411.15100">XGrammar: Flexible and Efficient Structured Generation Engine for Large Language Models</a> ‚Äî Yixin Dong et al., arXiv:2411.15100 (technical paper with benchmarks)</li>
<li><a href="https://github.com/mlc-ai/xgrammar">xgrammar GitHub</a> ‚Äî Fast, flexible structured generation library</li>
<li><a href="https://xgrammar.mlc.ai/docs/">xgrammar Documentation</a> ‚Äî Official docs with quick start guide</li>
<li><a href="https://xgrammar.mlc.ai/docs/start/quick_start">xgrammar Quick Start</a> ‚Äî Getting started with xgrammar</li>
<li><a href="https://blog.mlc.ai/2024/11/22/achieving-efficient-flexible-portable-structured-generation-with-xgrammar">Achieving Efficient Structured Generation with XGrammar</a> ‚Äî MLC blog post on xgrammar internals</li>
</ul>
<h3 id="vllm">vLLM</h3>
<ul>
<li><a href="https://docs.vllm.ai/en/latest/features/structured_outputs.html">vLLM Structured Outputs</a> ‚Äî Official documentation</li>
</ul>
<h3 id="demo-project">Demo Project</h3>
<ul>
<li><a href="https://github.com/slavadubrov/sgr-discount-manager">sgr-discount-manager</a> ‚Äî Working demo with all code examples from this post</li>
</ul>







  
  




  


 
  </article>
</div>

          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        
<div class="md-social">
  
    
    
    
    
    <a href="https://www.linkedin.com/in/slavadubrov" target="_blank" rel="noopener" title="LinkedIn" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://slavadubrov.substack.com/" target="_blank" rel="noopener" title="Substack" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M22.539 8.242H1.46V5.406h21.08zM1.46 10.812V24L12 18.11 22.54 24V10.812zM22.54 0H1.46v2.836h21.08z"/></svg>
    </a>
  
    
    
    
    
    <a href="https://github.com/slavadubrov" target="_blank" rel="noopener" title="GitHub" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
    <a href="/feed_rss_created.xml" target="_blank" rel="noopener" title="RSS" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M6.18 15.64a2.18 2.18 0 0 1 2.18 2.18C8.36 19 7.38 20 6.18 20 5 20 4 19 4 17.82a2.18 2.18 0 0 1 2.18-2.18M4 4.44A15.56 15.56 0 0 1 19.56 20h-2.83A12.73 12.73 0 0 0 4 7.27zm0 5.66a9.9 9.9 0 0 1 9.9 9.9h-2.83A7.07 7.07 0 0 0 4 12.93z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../../../..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.path", "navigation.indexes", "navigation.toc", "navigation.toc.sticky", "navigation.toc.maxdepth", "navigation.toc.title", "navigation.toc.collapse", "navigation.toc.collapse_empty_groups", "navigation.toc.collapse_single_children", "content.code.copy"], "search": "../../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.min.js"></script>
      
        <script src="../../../../../javascripts/mermaid-init.js"></script>
      
    
  </body>
</html>