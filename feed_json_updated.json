{"version": "https://jsonfeed.org/version/1", "title": "Shared Intelligence: Tips & Tricks in Machine Learning", "home_page_url": "https://slavadubrov.github.io/", "feed_url": "https://slavadubrov.github.io/feed_json_updated.json", "description": null, "icon": null, "authors": [], "language": "en", "items": [{"id": "https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/", "url": "https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/", "title": "Managing Python on macOS with uv", "content_html": "<h1>Managing Python like an AI Engineer on macOS with <strong>uv</strong></h1>\n<h2>TL;DR Bash\u00a0Cheat\u2011sheet</h2>\n<p><code>bash\nbrew install uv        # install tool\nuv python install 3.12 # grab interpreter\nuv python pin          # lock version for repo\nuv venv                # create .venv\nuv pip install numpy pandas   # ML staples\nuv run train.py        # run with correct interpreter\nuv self upgrade        # update uv itself</code></p>\n<hr>", "image": null, "date_modified": "2025-05-04T19:56:07+00:00", "authors": [], "tags": ["Python", "Tooling", "Tutorial"]}, {"id": "https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/", "url": "https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/", "title": "Setting up a MacBook for AI Engineering", "content_html": "<h1>Setting up a MacBook for AI Engineering</h1>\n<p>Here\u2019s my distilled, 10\u2011step workflow to transform a vanilla macOS install into a ready to-go AI engineering working station.</p>", "image": null, "date_modified": "2025-05-04T19:56:07+00:00", "authors": [], "tags": ["Mac", "Tutorial"]}, {"id": "https://slavadubrov.github.io/blog/2025/04/28/scaling-large-language-models-multi-gpu-and-multi-node-strategies-in-2025/", "url": "https://slavadubrov.github.io/blog/2025/04/28/scaling-large-language-models-multi-gpu-and-multi-node-strategies-in-2025/", "title": "Scaling Large Language Models. Multi-GPU and Multi-Node Strategies in 2025", "content_html": "<h1>Scaling Large Language Models. Multi-GPU and Multi-Node Strategies in 2025</h1>\n<p>As LLMs continue to grow in complexity and size, efficient training and inference require leveraging multiple GPUs and, often, multiple systems. This guide explores prevalent strategies and tools in 2025 that facilitate such scalability, incorporating insights from Hugging Face's <a href=\"https://huggingface.co/spaces/nanotron/ultrascale-playbook\">Ultra-Scale Playbook</a>.</p>", "image": null, "date_modified": "2025-05-04T19:56:07+00:00", "authors": [], "tags": ["Deep Learning", "Distributed Training", "GPU", "LLM", "Parallelism"]}]}