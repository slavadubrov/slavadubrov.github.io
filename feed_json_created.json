{"version": "https://jsonfeed.org/version/1", "title": "Shared Intelligence: Tips & Tricks in Machine Learning", "home_page_url": "https://slavadubrov.github.io/", "feed_url": "https://slavadubrov.github.io/feed_json_created.json", "description": null, "icon": null, "authors": [], "language": "en", "items": [{"id": "https://slavadubrov.github.io/blog/2025/05/07/quick-guide-on-zprofile-vs-zshrc-/", "url": "https://slavadubrov.github.io/blog/2025/05/07/quick-guide-on-zprofile-vs-zshrc-/", "title": "Quick-Guide on ~/.zprofile vs ~/.zshrc \ud83d\ude80", "content_html": "<h1>Quick-Guide on ~/.zprofile vs ~/.zshrc \ud83d\ude80</h1>\n<h2>TL;DR \u26a1</h2>\n<ul>\n<li><strong><code>~/.zprofile</code></strong> \u2192 one-shot, login-shell initialization (think \"environment/bootstrap\") \ud83d\udd27</li>\n<li><strong><code>~/.zshrc</code></strong> \u2192 every interactive prompt (think \"daily driving experience\") \ud83c\udfae</li>\n</ul>\n<p>Use both in tandem: keep your environment reliable with <strong><code>~/.zprofile</code></strong>, and your shell pleasant and tweakable with <strong><code>~/.zshrc</code></strong> \u2728</p>", "image": null, "date_published": "2025-05-07T00:00:00+00:00", "authors": [], "tags": ["guide", "macos", "tooling"]}, {"id": "https://slavadubrov.github.io/blog/2025/05/06/mlops-in-the-age-of-foundation-models-evolving-infrastructure-for-llms-and-beyond/", "url": "https://slavadubrov.github.io/blog/2025/05/06/mlops-in-the-age-of-foundation-models-evolving-infrastructure-for-llms-and-beyond/", "title": "MLOps in the Age of Foundation Models. Evolving Infrastructure for LLMs and Beyond", "content_html": "<h1>MLOps in the Age of Foundation Models. Evolving Infrastructure for LLMs and Beyond</h1>\n<p>The field of machine learning has undergone a seismic shift with the rise of large-scale foundation models - from giant language models (LLMs) like GPT-4 to image diffusion models like Stable Diffusion. As a result, the way we build and operate ML systems (MLOps) looks very different today than it did just a few years ago. In this post, we'll explore how ML infrastructure and MLOps practices have evolved - contrasting the \"classic\" era of MLOps with the modern paradigms emerging to support foundation models. We'll highlight what's changed, what new patterns and workflows have emerged.</p>", "image": null, "date_published": "2025-05-06T00:00:00+00:00", "authors": [], "tags": ["infrastructure", "llmops", "mlops"]}, {"id": "https://slavadubrov.github.io/blog/2025/05/04/scaling-large-language-models---practical-multi-gpu-and-multi-node-strategies-for-2025/", "url": "https://slavadubrov.github.io/blog/2025/05/04/scaling-large-language-models---practical-multi-gpu-and-multi-node-strategies-for-2025/", "title": "Scaling Large Language Models - Practical Multi-GPU and Multi-Node Strategies for 2025", "content_html": "<h1>Scaling Large Language Models - Practical Multi-GPU and Multi-Node Strategies for 2025</h1>\n<p>The race to build bigger, better language models continues at breakneck speed. Today's state-of-the-art models require massive computing resources that no single GPU can handle. Whether you're training a custom LLM or deploying one for inference, understanding how to distribute this workload is essential.</p>\n<p>This guide walks through practical strategies for scaling LLMs across multiple GPUs and nodes, incorporating insights from Hugging Face's <a href=\"https://huggingface.co/spaces/nanotron/ultrascale-playbook\">Ultra-Scale Playbook</a>.</p>", "image": null, "date_published": "2025-05-04T00:00:00+00:00", "authors": [], "tags": ["Deep Learning", "Distributed Training", "GPU", "LLM", "Parallelism"]}, {"id": "https://slavadubrov.github.io/blog/2025/04/19/quick-guide-on-setting-up-a-macbook-for-ai-engineering/", "url": "https://slavadubrov.github.io/blog/2025/04/19/quick-guide-on-setting-up-a-macbook-for-ai-engineering/", "title": "Quick-Guide on setting up a MacBook for AI Engineering", "content_html": "<h1>Quick-Guide on setting up a MacBook for AI Engineering</h1>\n<p>Here\u2019s my distilled, 10\u2011step workflow to transform a vanilla macOS install into a ready to-go AI engineering working station.</p>", "image": null, "date_published": "2025-04-19T00:00:00+00:00", "authors": [], "tags": ["guide", "macos", "tooling"]}, {"id": "https://slavadubrov.github.io/blog/2025/04/17/quick-guide-on-managing-python-on-macos-with-uv/", "url": "https://slavadubrov.github.io/blog/2025/04/17/quick-guide-on-managing-python-on-macos-with-uv/", "title": "Quick-Guide on managing Python on macOS with uv", "content_html": "<h1>Quick-Guide on managing Python like an AI Engineer on macOS with <strong>uv</strong></h1>\n<h2>TL;DR Bash\u00a0Cheat\u2011sheet</h2>\n<p><code>bash\nbrew install uv        # install tool\nuv python install 3.12 # grab interpreter\nuv python pin          # lock version for repo\nuv venv                # create .venv\nuv pip install numpy pandas   # ML staples\nuv run train.py        # run with correct interpreter\nuv self upgrade        # update uv itself</code></p>\n<hr>", "image": null, "date_published": "2025-04-17T00:00:00+00:00", "authors": [], "tags": ["guide", "python", "tooling"]}]}