<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>Shared Intelligence: Tips &amp; Tricks in Machine Learning</title><link>https://slavadubrov.github.io/</link><atom:link href="https://slavadubrov.github.io/feed_rss_created.xml" rel="self" type="application/rss+xml" /><language>en</language> <pubDate>Mon, 05 May 2025 20:52:27 -0000</pubDate> <lastBuildDate>Mon, 05 May 2025 20:52:27 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.1</generator> <image> <url>None</url> <title>Shared Intelligence: Tips & Tricks in Machine Learning</title><link>https://slavadubrov.github.io/</link> </image> <item> <title>MLOps in the Age of Foundation Models. Evolving Infrastructure for LLMs and Beyond</title> <category>infrastructure</category> <category>llmops</category> <category>mlops</category> <description>&lt;h1&gt;MLOps in the Age of Foundation Models. Evolving Infrastructure for LLMs and Beyond&lt;/h1&gt;&lt;p&gt;The field of machine learning has undergone a seismic shift with the rise of large-scale foundation models - from giant language models (LLMs) like GPT-4 to image diffusion models like Stable Diffusion. As a result, the way we build and operate ML systems (MLOps) looks very different today than it did just a few years ago. In this post, we&#39;ll explore how ML infrastructure and MLOps practices have evolved - contrasting the &#34;classic&#34; era of MLOps with the modern paradigms emerging to support foundation models. We&#39;ll highlight what&#39;s changed, what new patterns and workflows have emerged.&lt;/p&gt;</description><link>https://slavadubrov.github.io/blog/2025/05/06/mlops-in-the-age-of-foundation-models-evolving-infrastructure-for-llms-and-beyond/</link> <pubDate>Tue, 06 May 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/05/06/mlops-in-the-age-of-foundation-models-evolving-infrastructure-for-llms-and-beyond/</guid> </item> <item> <title>Scaling Large Language Models - Practical Multi-GPU and Multi-Node Strategies for 2025</title> <category>Deep Learning</category> <category>Distributed Training</category> <category>GPU</category> <category>LLM</category> <category>Parallelism</category> <description>&lt;h1&gt;Scaling Large Language Models - Practical Multi-GPU and Multi-Node Strategies for 2025&lt;/h1&gt;&lt;p&gt;The race to build bigger, better language models continues at breakneck speed. Today&#39;s state-of-the-art models require massive computing resources that no single GPU can handle. Whether you&#39;re training a custom LLM or deploying one for inference, understanding how to distribute this workload is essential.&lt;/p&gt;&lt;p&gt;This guide walks through practical strategies for scaling LLMs across multiple GPUs and nodes, incorporating insights from Hugging Face&#39;s &lt;a href=&#34;https://huggingface.co/spaces/nanotron/ultrascale-playbook&#34;&gt;Ultra-Scale Playbook&lt;/a&gt;.&lt;/p&gt;</description><link>https://slavadubrov.github.io/blog/2025/05/04/scaling-large-language-models---practical-multi-gpu-and-multi-node-strategies-for-2025/</link> <pubDate>Sun, 04 May 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/05/04/scaling-large-language-models---practical-multi-gpu-and-multi-node-strategies-for-2025/</guid> </item> <item> <title>Setting up a MacBook for AI Engineering</title> <category>Mac</category> <category>Tutorial</category> <description>&lt;h1&gt;Setting up a MacBook for AI Engineering&lt;/h1&gt;&lt;p&gt;Here’s my distilled, 10‑step workflow to transform a vanilla macOS install into a ready to-go AI engineering working station.&lt;/p&gt;</description><link>https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/</link> <pubDate>Sat, 19 Apr 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/</guid> </item> <item> <title>Managing Python on macOS with uv</title> <category>Python</category> <category>Tooling</category> <category>Tutorial</category> <description>&lt;h1&gt;Managing Python like an AI Engineer on macOS with &lt;strong&gt;uv&lt;/strong&gt;&lt;/h1&gt;&lt;h2&gt;TL;DR Bash Cheat‑sheet&lt;/h2&gt;&lt;p&gt;&lt;code&gt;bashbrew install uv # install tooluv python install 3.12 # grab interpreteruv python pin # lock version for repouv venv # create .venvuv pip install numpy pandas # ML staplesuv run train.py # run with correct interpreteruv self upgrade # update uv itself&lt;/code&gt;&lt;/p&gt;&lt;hr&gt;</description><link>https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/</link> <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/</guid> </item> </channel></rss>