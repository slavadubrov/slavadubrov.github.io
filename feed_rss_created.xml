<?xml version="1.0" encoding="UTF-8" ?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"> <channel><title>Shared Intelligence: Tips &amp; Tricks in Machine Learning</title><link>https://slavadubrov.github.io/</link><atom:link href="https://slavadubrov.github.io/feed_rss_created.xml" rel="self" type="application/rss+xml" /><language>en</language> <pubDate>Sun, 04 May 2025 19:56:24 -0000</pubDate> <lastBuildDate>Sun, 04 May 2025 19:56:24 -0000</lastBuildDate> <ttl>1440</ttl> <generator>MkDocs RSS plugin - v1.17.1</generator> <image> <url>None</url> <title>Shared Intelligence: Tips & Tricks in Machine Learning</title><link>https://slavadubrov.github.io/</link> </image> <item> <title>Scaling Large Language Models. Multi-GPU and Multi-Node Strategies in 2025</title> <category>Deep Learning</category> <category>Distributed Training</category> <category>GPU</category> <category>LLM</category> <category>Parallelism</category> <description>&lt;h1&gt;Scaling Large Language Models. Multi-GPU and Multi-Node Strategies in 2025&lt;/h1&gt;&lt;p&gt;As LLMs continue to grow in complexity and size, efficient training and inference require leveraging multiple GPUs and, often, multiple systems. This guide explores prevalent strategies and tools in 2025 that facilitate such scalability, incorporating insights from Hugging Face&#39;s &lt;a href=&#34;https://huggingface.co/spaces/nanotron/ultrascale-playbook&#34;&gt;Ultra-Scale Playbook&lt;/a&gt;.&lt;/p&gt;</description><link>https://slavadubrov.github.io/blog/2025/04/28/scaling-large-language-models-multi-gpu-and-multi-node-strategies-in-2025/</link> <pubDate>Mon, 28 Apr 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/04/28/scaling-large-language-models-multi-gpu-and-multi-node-strategies-in-2025/</guid> </item> <item> <title>Setting up a MacBook for AI Engineering</title> <category>Mac</category> <category>Tutorial</category> <description>&lt;h1&gt;Setting up a MacBook for AI Engineering&lt;/h1&gt;&lt;p&gt;Here’s my distilled, 10‑step workflow to transform a vanilla macOS install into a ready to-go AI engineering working station.&lt;/p&gt;</description><link>https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/</link> <pubDate>Sat, 19 Apr 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/04/19/setting-up-a-macbook-for-ai-engineering/</guid> </item> <item> <title>Managing Python on macOS with uv</title> <category>Python</category> <category>Tooling</category> <category>Tutorial</category> <description>&lt;h1&gt;Managing Python like an AI Engineer on macOS with &lt;strong&gt;uv&lt;/strong&gt;&lt;/h1&gt;&lt;h2&gt;TL;DR Bash Cheat‑sheet&lt;/h2&gt;&lt;p&gt;&lt;code&gt;bashbrew install uv # install tooluv python install 3.12 # grab interpreteruv python pin # lock version for repouv venv # create .venvuv pip install numpy pandas # ML staplesuv run train.py # run with correct interpreteruv self upgrade # update uv itself&lt;/code&gt;&lt;/p&gt;&lt;hr&gt;</description><link>https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/</link> <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><source url="https://slavadubrov.github.io/feed_rss_created.xml">Shared Intelligence: Tips & Tricks in Machine Learning</source><guid isPermaLink="true">https://slavadubrov.github.io/blog/2025/04/17/managing-python-on-macos-with-uv/</guid> </item> </channel></rss>